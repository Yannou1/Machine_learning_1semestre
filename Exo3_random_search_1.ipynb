{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Search Implementation\n",
    "\n",
    "In this exercise we will implement the random search algorithm from scratch. \n",
    "\n",
    "The goal is to understand how the hyperparameter tunning is performed. \n",
    "\n",
    "You will receive a dictionary of {parameter_name:values} to be used with a decision tree classifier.\n",
    "\n",
    "Your algorithm need to randomly choose a combination of parameters and use it as input to train the Decision Tree.\n",
    "\n",
    "The algorithm will choose n random combinations. n is a parameter given by the user.\n",
    "\n",
    "You can use the following code to help your implementation or you can write your code from scratch.\n",
    "\n",
    "Needles to say you should not use the \"RandomizedSearchCV\" from scikit-learn\n",
    "\n",
    "Hands on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:  (455, 30) (455,)\n",
      "Testing set:  (114, 30) (114,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-39 {color: black;}#sk-container-id-39 pre{padding: 0;}#sk-container-id-39 div.sk-toggleable {background-color: white;}#sk-container-id-39 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-39 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-39 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-39 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-39 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-39 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-39 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-39 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-39 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-39 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-39 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-39 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-39 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-39 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-39 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-39 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-39 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-39 div.sk-item {position: relative;z-index: 1;}#sk-container-id-39 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-39 div.sk-item::before, #sk-container-id-39 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-39 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-39 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-39 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-39 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-39 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-39 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-39 div.sk-label-container {text-align: center;}#sk-container-id-39 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-39 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-39\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(min_samples_split=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" checked><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(min_samples_split=4)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(min_samples_split=4)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "print(\"Training set: \", X_train.shape, y_train.shape)\n",
    "print(\"Testing set: \", X_test.shape, y_test.shape)\n",
    "\n",
    "def random_search(model, param_grid, X, y, n_iter=100):\n",
    "    \"\"\"\n",
    "    Perform random search\n",
    "    :param model: Model to be used\n",
    "    :param param_grid: Dictionary containing hyperparameters and their possible values\n",
    "    :param X: Data (n_samples, n_features)\n",
    "    :param y: Target (n_samples,)\n",
    "    :param n_iter: Number of iterations\n",
    "    :return: Best hyperparameters\n",
    "    \"\"\"\n",
    "    M_precision = 0\n",
    "    for _ in range(n_iter):\n",
    "    # generation random du parametre depuis le dictionnaire\n",
    "        parametres = {\n",
    "            \"max_depth\": np.random.choice(param_grid[\"max_depth\"]),\n",
    "            \"criterion\": np.random.choice(param_grid[\"criterion\"]),\n",
    "            \"min_samples_split\": np.random.choice(param_grid[\"min_samples_split\"]),\n",
    "        }\n",
    "    # On definis les paramétre de maniére aléatoire du model\n",
    "    model.set_params(**parametres)\n",
    "\n",
    "    #on entraine le model avec X_train, y_train \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # on prédit les valeur afin de connaitre par la suite la précision des parameter\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # On calcul l'accuracy afin d'avoir les parametre optimaux\n",
    "    precision = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # On vérifie que la nouvelle précission ne soit pas inférieur a l'ancienne\n",
    "    if precision > M_precision:\n",
    "        M_precision = precision\n",
    "        M_parametres = parametres\n",
    "    return M_parametres\n",
    "\n",
    "# Define model and hyperparameters\n",
    "model = DecisionTreeClassifier()\n",
    "param_grid = {\n",
    "    \"max_depth\": [3, 5, 7, None],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"min_samples_split\": [2, 3, 4, 5],\n",
    "}\n",
    "\n",
    "# Perform random search\n",
    "Param_final = random_search(model, param_grid, X, y, n_iter=100)\n",
    "\n",
    "# Train the model with best hyperparameter \n",
    "# ces deux lignes permette d'afficher les output des parametre optimaux\n",
    "model.set_params(**Param_final)\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "914a73f32d308ae8debcaf6a2c2af8e68613f922620f6864a793ea7cdc2482ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
